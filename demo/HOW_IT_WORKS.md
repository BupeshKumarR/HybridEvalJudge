# How This Demo Works

## ğŸ¯ What It Does

This demo **compares multiple AI models** to see which one gives the best answers.

### Simple Example

**Question:** "What are the symptoms of diabetes?"

**Model A (Phi-3):** Lists 8 accurate symptoms â†’ **Score: 87/100** âœ…  
**Model B (Llama 3.2):** Lists 6 accurate symptoms â†’ **Score: 82/100** âœ…  
**Model C (Qwen2.5):** Lists 5 accurate symptoms â†’ **Score: 79/100** âš ï¸

**Winner:** Model A (Phi-3) is the most accurate!

---

## ğŸ”„ The Workflow

```
1. Setup Phase
   â†“
   [Detect your system specs]
   â†“
   [Recommend best models for your RAM]
   â†“
   [Install models via Ollama]

2. Evaluation Phase
   â†“
   [Ask all models the same question]
   â†“
   [Collect their responses]
   â†“
   [Compare against trusted reference]
   â†“
   [Score each model (0-100)]
   â†“
   [Rank models by performance]

3. Results Phase
   â†“
   [Display rankings]
   â†“
   [Save to results.json]
   â†“
   [Show recommendation]
```

---

## ğŸš€ How to Try It

### Step 1: Install Ollama (2 minutes)

Ollama lets you run AI models locally on your laptop.

```bash
# Visit https://ollama.ai
# Download and install for your OS
```

### Step 2: Setup Models (3 minutes)

This detects your RAM and installs the best models:

```bash
python demo/setup.py
```

**What happens:**
- Checks your system (RAM, CPU, OS)
- Recommends 2-3 models based on your specs
- Downloads them (2-6GB total)

### Step 3: Run Demo (30 seconds)

```bash
python demo/demo.py
```

**What you'll see:**
- Models being tested in real-time
- Their responses
- Scores and rankings
- Which model is best

---

## ğŸ“Š Example Output

```
================================================================================
ğŸ” LLM Judge Auditor - Multi-Model Evaluation Demo
================================================================================

âœ… Available Models:
   âœ… phi3
   âœ… llama3.2:3b
   âœ… qwen2.5:3b

ğŸ¯ Testing 3 models...

ğŸ“ Test Question:
   What are the early warning signs of Type 2 diabetes?

ğŸ¤– Generating responses...
   ğŸ“± phi3... (12.8s) âœ… Generated 1050 characters
   ğŸ“± llama3.2:3b... (8.9s) âœ… Generated 1088 characters
   ğŸ“± qwen2.5:3b... (7.7s) âœ… Generated 2030 characters

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“‹ EVALUATION RESULTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ† Model Rankings:
   ğŸ¥‡ 1. phi3: 87.3/100 (Confidence: 0.91)
   ğŸ¥ˆ 2. llama3.2:3b: 82.1/100 (Confidence: 0.88)
   ğŸ¥‰ 3. qwen2.5:3b: 79.5/100 (Confidence: 0.85)

ğŸ¯ RECOMMENDATION:
   Best Model: phi3
   Score: 87.3/100
   Verdict: APPROVED âœ…

ğŸ“ Results saved to: demo/results.json
```

---

## ğŸ“ Why This Matters

### Real-World Use Cases

**Healthcare App:**
- Need to choose which AI model to use for medical advice
- This demo shows Phi-3 is most accurate for health questions
- Deploy Phi-3 instead of less accurate models

**Customer Support:**
- Testing which model gives best product answers
- Compare 3 models, pick the winner
- Save money by using the best free model

**Education Platform:**
- Which AI tutor is most accurate?
- Test them all, deploy the best one
- Ensure students get correct information

---

## ğŸ”§ Customization

### Test Your Own Questions

Edit `demo/demo.py` around line 150:

```python
# Change this:
question = "What are the early warning signs of Type 2 diabetes?"

# To your question:
question = "How does photosynthesis work?"
question = "What are the symptoms of anxiety?"
question = "Explain quantum computing"
```

### Change the Reference

```python
# Add your trusted reference information:
reference = """
Your expert knowledge here.
This is what the AI should say.
"""
```

The demo compares AI responses against your reference.

---

## ğŸ’» System Requirements

| Your RAM | Models Installed | Speed |
|----------|-----------------|-------|
| 8GB | 2 small models | Good |
| 16GB | 3 medium models | Great |
| 32GB+ | 4+ models | Excellent |

The setup script automatically picks the right models for your system.

---

## ğŸ†“ Why It's Free

- **No API keys** - Everything runs locally
- **No subscriptions** - Models are open source
- **No limits** - Run as many evaluations as you want
- **No data sent** - 100% private and offline

---

## ğŸ› Common Issues

### "Ollama not found"
**Solution:** Install Ollama from https://ollama.ai

### "Model not found"
**Solution:** Run `python demo/setup.py` first

### "Out of memory"
**Solution:** Close other apps or use smaller models

### "Slow performance"
**Solution:** Normal! First run downloads models (one-time)

---

## ğŸ“š What's Next?

1. **Run the demo** - See it in action
2. **Try different questions** - Test various topics
3. **Compare results** - See which model is best for your use case
4. **Integrate** - Use the best model in your project

---

## ğŸ¯ Summary

**This demo helps you:**
- âœ… Test multiple AI models
- âœ… Compare them objectively
- âœ… Pick the best one for your needs
- âœ… All for free, running locally

**Time:** 5 minutes to setup  
**Cost:** $0  
**Value:** Know which AI model is best for your project! ğŸ’
