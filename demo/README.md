# LLM Judge Auditor - Demo

**Professional LLM evaluation using FREE local models - zero cost, no API keys!**

This demo shows how to evaluate and compare multiple AI models running locally on your laptop.

---

## âš¡ Quick Start (5 Minutes)

**Just 3 commands:**

```bash
# 1. Install Ollama from https://ollama.ai (2 min)

# 2. Setup models (3 min)
python demo/setup.py

# 3. Run demo (30 sec)
python demo/demo.py
```

**That's it!** Professional LLM evaluation running locally.

---

## ğŸ“‹ Detailed Setup

### Step 1: Install Ollama (2 minutes)

Visit [https://ollama.ai](https://ollama.ai) and download for your OS.

### Step 2: Setup Models (3 minutes)

```bash
python demo/setup.py
```

This auto-detects your system and installs the best models for your RAM.

### Step 3: Run Demo (30 seconds)

```bash
python demo/demo.py
```

**Done!** You now have professional LLM evaluation running locally.

---

## ğŸ“Š What It Does

The demo:
- âœ… Tests multiple local models (Phi-3, Llama 3.2, Qwen2.5)
- âœ… Generates real AI responses (not simulated)
- âœ… Evaluates quality and accuracy
- âœ… Compares models objectively
- âœ… Ranks by performance
- âœ… Saves results to `demo/results.json`

### Example Output

```
ğŸ† Model Rankings:
   ğŸ¥‡ 1. phi3: 87.3/100 (Confidence: 0.91)
   ğŸ¥ˆ 2. llama3.2:3b: 82.1/100 (Confidence: 0.88)
   ğŸ¥‰ 3. qwen2.5:3b: 79.5/100 (Confidence: 0.85)

ğŸ¯ RECOMMENDATION:
   Best Model: phi3
   Verdict: APPROVED âœ…
```

---

## ğŸ’» System Requirements

| RAM | Recommended Models | Performance |
|-----|-------------------|-------------|
| 8GB | phi3 + llama3.2:1b | Good |
| 16GB | phi3 + llama3.2:3b + qwen2.5:3b | Excellent |
| 32GB+ | All above + mistral | Production-grade |

The setup script automatically recommends the best models for your system.

---

## ğŸ¯ Perfect For

### Portfolio Projects
- Demonstrate multi-agent AI systems
- Show model comparison capabilities
- Prove evaluation expertise

### Resume Highlights
- "Built multi-agent LLM evaluation system"
- "Implemented AI quality assessment pipeline"
- "Developed zero-cost model comparison framework"

### Learning & Development
- Understand LLM evaluation
- Compare model capabilities
- Experiment safely offline

### Privacy-Sensitive Work
- Healthcare applications
- Legal document review
- Financial analysis
- 100% local processing

---

## ğŸ”§ Customization

### Test Your Own Questions

Edit `demo/demo.py` around line 150:

```python
question = "Your custom question here"
reference = "Your trusted reference information"
```

### Add More Models

```bash
ollama pull mistral      # 7B model (if 16GB+ RAM)
ollama pull codellama    # For code evaluation
ollama pull gemma:2b     # Very small model
```

They'll automatically appear in the demo!

---

## ğŸ“š Documentation

- **[HOW_IT_WORKS.md](HOW_IT_WORKS.md)** â­ - Detailed explanation with examples
- **[QUICK_START_FREE.md](QUICK_START_FREE.md)** - 5-minute quick start
- **[FREE_SETUP_GUIDE.md](FREE_SETUP_GUIDE.md)** - Complete setup guide
- **[FREE_DEMO_SUMMARY.md](FREE_DEMO_SUMMARY.md)** - Full feature overview

---

## ğŸ› Troubleshooting

### "Ollama not found"
```bash
# Check installation
which ollama

# Reinstall from https://ollama.ai
```

### "Model not found"
```bash
# List installed models
ollama list

# Pull missing model
ollama pull phi3
```

### "Out of memory"
```bash
# Use smaller model
ollama pull llama3.2:1b

# Or close other applications
```

---

## ğŸ’¡ Why This Demo?

### Zero Cost
- âœ… No API keys
- âœ… No subscriptions
- âœ… Free forever
- âœ… Runs offline

### Professional Quality
- âœ… Multi-model comparison
- âœ… Objective evaluation
- âœ… Confidence scoring
- âœ… Comprehensive reporting

### Privacy First
- âœ… 100% local processing
- âœ… No data sent to cloud
- âœ… Full control
- âœ… GDPR/HIPAA compatible

---

## ğŸš€ Next Steps

1. **Today**: Run the demo with different questions
2. **This Week**: Customize for your domain
3. **This Month**: Add to your portfolio/GitHub
4. **Share**: Show it off on LinkedIn!

---

## ğŸ“ Support

- **Main Docs**: [../README.md](../README.md)
- **Examples**: [../examples/](../examples/)
- **Issues**: GitHub Issues

---

**Total setup time: 5 minutes**  
**Total cost: $0**  
**Professional value: Priceless** ğŸ’
